import time

import cv2
from omegaconf import OmegaConf
from sleap_nn.inference.predictors import SingleInstancePredictor
import os
import numpy as np
import sleap_io as sio
import tempfile
import math
from sleap_io.model.skeleton import Skeleton, Node, Edge

# ä½ çš„æ¨¡å‹ç›®å½•ï¼ˆé‡Œé¢æœ‰ best.ckpt å’Œ training_config.yamlï¼‰
MODEL_DIR = r"D:\251016_124032.single_instance.n=26"

yaml_path = None
for name in ("training_config.yaml", "initial_config.yaml"):
    p = os.path.join(MODEL_DIR, name)
    if os.path.isfile(p):
        yaml_path = p
        break
if yaml_path is None:
    raise FileNotFoundError("æœªåœ¨æ¨¡å‹ç›®å½•ä¸­æ‰¾åˆ° training_config.yaml æˆ– initial_config.yaml")
print(yaml_path)
pre_cfg = OmegaConf.load(yaml_path)
nodes = pre_cfg["data_config"]["skeletons"][0]["nodes"]
print(nodes)
edges = pre_cfg["data_config"]["skeletons"][0]["edges"]
print(edges)
NODE_NAMES = [getattr(n, "name", None) or (n["name"] if isinstance(n, dict) else str(n)) for n in nodes]
print(NODE_NAMES)
list_of_edges = []
list_of_nodes = [Node(name=n) for n in NODE_NAMES]
name_to_node = {n.name: n for n in list_of_nodes}
for edge in edges:
    source_node = name_to_node[edge["source"]["name"]]
    target_node = name_to_node[edge["destination"]["name"]]
    list_of_edges.append(Edge(source = source_node, destination = target_node))
print(list_of_edges)

skel = Skeleton(nodes=list_of_nodes,edges=list_of_edges)
print(skel)
defaults = {
    "max_height": 1080,                    # ä½ ä¹Ÿå¯æ”¹æˆæ‘„åƒå¤´é«˜åº¦æˆ–è®­ç»ƒæ—¶å°ºå¯¸
    "max_width": 1920,
    "resize_input_to_multiple_of": 16,    # ä¸€èˆ¬ä¸ max_stride ä¸€è‡´
    "pad_to_stride": 16,

    # é¢œè‰²ä¸æ ¼å¼æ§åˆ¶
    "ensure_rgb": False,           # ä½ å·²è‡ªå·±è½¬æ¢ä¸º RGB
    "normalize_color": True,
    "convert_range": False,        # è‹¥è®­ç»ƒæ—¶æ²¡æ ‡å‡†åŒ–åˆ° 0â€“1ï¼Œåˆ™ä¿æŒ False
    "clip_input_range": True,
    "ensure_grayscale": False,

    # ç¼©æ”¾ä¸æ ‡å‡†åŒ–
    "scale": 1.0,                  # ç¼©æ”¾ç³»æ•°
    "normalize_input": False,
    "normalize_input_range": False,
    "standardize_input": False,

    # å‡ ä½•å˜æ¢ç›¸å…³
    "square": False,
    "center_on_largest": True,
    "rotation": 0.0,
    "flip": False,

    # å…¶ä»–æ½œåœ¨å­—æ®µï¼ˆéƒ¨åˆ†æ¨¡å‹è®­ç»ƒè„šæœ¬ä¼šè®¿é—®ï¼‰
    "crop": None,
    "crop_pad": 0,
    "stride": 16,
    "max_stride": 16,
    "dtype": "uint8",
}
for k, v in defaults.items():
    if k not in pre_cfg["data_config"]["preprocessing"] is None:
        pre_cfg["data_config"]["preprocessing"][k] = v
        print(k)

predictor = SingleInstancePredictor.from_trained_models(
    confmap_ckpt_path = MODEL_DIR,
    preprocess_config = pre_cfg["data_config"]["preprocessing"],
    device="cuda"              # æ²¡æœ‰GPUå°±æ”¹ä¸º "cpu"
)

cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)
# å¯é€‰ï¼šè®¾ç½®åˆ†è¾¨ç‡
# cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
tmp_dir = tempfile.gettempdir()
tmp_path = os.path.join(tmp_dir, "tmp_frame.png")
def xy_from_pt(pt):
    """å°† SLEAP çš„ pointï¼ˆå¯èƒ½æ˜¯ç»“æ„åŒ–æ ‡é‡/ndarray/å¯¹è±¡ï¼‰å®‰å…¨è½¬æˆ (x, y)ã€‚"""
    if pt is None:
        return None

    # 1) ç»“æ„åŒ– numpy æ ‡é‡æˆ–æ•°ç»„ï¼šä¼˜å…ˆå– ['xy']
    if isinstance(pt, np.void) and getattr(pt, "dtype", None) is not None and pt.dtype.fields:
        if "xy" in pt.dtype.fields:
            x, y = pt["xy"]
            if math.isnan(x) or math.isnan(y):
                return None
            return int(round(float(x))), int(round(float(y)))

    if isinstance(pt, np.ndarray) and pt.dtype.fields:
        # ç»“æ„åŒ– ndarrayï¼ˆå¾ˆå°‘è§ï¼Œé˜²å¾¡æ€§å¤„ç†ï¼‰
        if "xy" in pt.dtype.fields:
            xy = pt["xy"]
            # å¯èƒ½æ˜¯æ ‡é‡æˆ–(1,2)ä¹‹ç±»
            xy = np.asarray(xy).astype(float).ravel()
            if xy.size < 2 or np.any(np.isnan(xy[:2])):
                return None
            return int(round(xy[0])), int(round(xy[1]))

    # 2) å¯¹è±¡æœ‰å±æ€§ .xy æˆ– .x/.y
    if hasattr(pt, "xy"):
        x, y = pt.xy
        if math.isnan(x) or math.isnan(y):
            return None
        return int(round(float(x))), int(round(float(y)))
    if hasattr(pt, "x") and hasattr(pt, "y"):
        x, y = pt.x, pt.y
        if math.isnan(x) or math.isnan(y):
            return None
        return int(round(float(x))), int(round(float(y)))

    # 3) å¸¸è§„ list/tuple/ndarray
    try:
        arr = np.asarray(pt, dtype=float).ravel()
        if arr.size < 2 or np.any(np.isnan(arr[:2])):
            return None
        return int(round(arr[0])), int(round(arr[1]))
    except Exception:
        return None
frame_count = 0
unrecognized_frames = 0
start = time.time()
while True:
    recognized = True
    ok, frame = cap.read()
    if not ok:
        break
    #cv2.imshow("frame", frame)
    rgb = frame[..., ::-1]
    #cv2.imshow("rgb", rgb)
    # vid = sio.Video.from_numpy(np.expand_dims(rgb, axis=0))  # (1, H, W, 3)
    cv2.imwrite(tmp_path, rgb)  # å†™å…¥ BGR å°±å¯ä»¥

    predictor.make_pipeline(tmp_path)  # æŒ‡å®šæ•°æ®æºï¼ˆè§†é¢‘å¯¹è±¡/æ–‡ä»¶è·¯å¾„/Labelsï¼‰
    labels = predictor.predict()  # è¿™é‡Œæ‰çœŸæ­£è·‘æ¨ç†ï¼ˆè¿”å› sio.Labelsï¼‰

    # ç”»å…³é”®ç‚¹ï¼ˆå®¹é”™ Noneï¼‰
    if labels and labels.labeled_frames:
        lf = labels.labeled_frames[0]
        for inst_id, inst in enumerate(lf.instances):
            #print(f"\nğŸŸ¢ Instance {inst_id}:")
            inst.skeleton = skel
            recognized_labels = 0
            for i, pt in enumerate(inst.points):
                xy = xy_from_pt(pt)  # ç”¨æˆ‘ä»¬åˆšæ‰å®šä¹‰çš„å®‰å…¨å–ç‚¹å‡½æ•°
                name = skel.nodes[i].name  # ç‚¹çš„æ ‡ç­¾å
                if xy is not None:
                    #print(f"  {i:02d} | {name or 'unnamed'} : {xy}")
                    recognized_labels += 1
                else:
                    #print(f"  {i:02d} | {name or 'unnamed'} : None")
                    recognized = False
                    continue
                x, y = xy
                cv2.circle(frame, (x, y), 3, (0, 255, 0), -1)
                cv2.putText(frame,name,(x + 8, y - 8),         # æ–‡å­—å·¦ä¸‹è§’åæ ‡ï¼ˆç¨å¾®åå³ä¸Šé˜²æ­¢é‡å ï¼‰
                cv2.FONT_HERSHEY_SIMPLEX,  # å­—ä½“
                0.5,                    # å­—ä½“å¤§å°
                (255, 0, 0),            # é¢œè‰²ï¼ˆç»¿è‰²ï¼‰
                1,                      # çº¿å®½
                cv2.LINE_AA)

            for i, j in skel.edge_inds:
                found_1st = False
                found_2nd = False
                if xy_from_pt(inst.points[i]) is not None:
                    x1, y1 = xy_from_pt(inst.points[i])
                    found_1st = True
                if xy_from_pt(inst.points[j]) is not None:
                    x2, y2 = xy_from_pt(inst.points[j])
                    found_2nd = True
                if found_1st and found_2nd:
                    cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
    if not recognized:
        unrecognized_frames += 1
        print(recognized_labels, "out of 9 labels are recognized.")
    cv2.imshow("SLEAP-NN Realtime", frame)
    frame_count += 1
    if cv2.waitKey(1) & 0xFF == 27:  # ESC é€€å‡º
        break
end = time.time()
print(frame_count/(end-start)," fps")
cap.release()
cv2.destroyAllWindows()
print((frame_count-unrecognized_frames)," frames are fully recognized from ",frame_count, " frames")
print("The recognition rate is ",(frame_count-unrecognized_frames)/frame_count*100,"%")

